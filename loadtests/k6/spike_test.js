/**
 * Spike Test - Test ƒë·ªôt bi·∫øn traffic ng·∫Øn h·∫°n
 * 
 * M·ª•c ƒë√≠ch:
 * - Ki·ªÉm tra h·ªá th·ªëng x·ª≠ l√Ω traffic surge ƒë·ªôt ng·ªôt (flash crowd)
 * - ƒê√°nh gi√° th·ªùi gian recovery sau spike
 * - Verify async queue ho·∫°t ƒë·ªông ƒë√∫ng trong spike scenario
 * 
 * C√°ch ch·∫°y:
 *   ACCESS_TOKEN=... k6 run --summary-export loadtests/results/spike_test.json loadtests/k6/spike_test.js
 * 
 * M√¥ h√¨nh: Normal ‚Üí Spike (5x) ‚Üí Normal ‚Üí Spike (10x) ‚Üí Normal
 */

import http from 'k6/http';
import { check, sleep } from 'k6';
import { Trend, Counter, Rate } from 'k6/metrics';

// Custom metrics
const tripLatency = new Trend('trip_create_latency', true);
const errorRate = new Rate('error_rate');
const spikeRecoveryTime = new Trend('spike_recovery_time', true);

const NORMAL_RPS = Number(__ENV.NORMAL_RPS) || 20;
const SPIKE_MULTIPLIER = Number(__ENV.SPIKE_MULTIPLIER) || 5;

export const options = {
  scenarios: {
    spike_pattern: {
      executor: 'ramping-arrival-rate',
      startRate: NORMAL_RPS,
      timeUnit: '1s',
      stages: [
        // Baseline normal load
        { target: NORMAL_RPS, duration: '30s' },
        
        // First spike - 5x normal
        { target: NORMAL_RPS * SPIKE_MULTIPLIER, duration: '10s' },
        { target: NORMAL_RPS * SPIKE_MULTIPLIER, duration: '30s' },
        
        // Recovery to normal
        { target: NORMAL_RPS, duration: '10s' },
        { target: NORMAL_RPS, duration: '30s' },
        
        // Second spike - 10x normal (extreme)
        { target: NORMAL_RPS * SPIKE_MULTIPLIER * 2, duration: '10s' },
        { target: NORMAL_RPS * SPIKE_MULTIPLIER * 2, duration: '20s' },
        
        // Final recovery
        { target: NORMAL_RPS, duration: '10s' },
        { target: NORMAL_RPS, duration: '30s' },
      ],
      preAllocatedVUs: 50,
      maxVUs: 300,
    },
  },
  thresholds: {
    // Cho ph√©p latency cao h∆°n trong spike, nh∆∞ng v·∫´n c√≥ gi·ªõi h·∫°n
    'http_req_duration': ['p(95)<3000'],
    'trip_create_latency': ['p(99)<5000'],
    // Error rate kh√¥ng ƒë∆∞·ª£c qu√° cao ngay c·∫£ trong spike
    'error_rate': ['rate<0.15'],
  },
};

const BASE_URL = __ENV.API_BASE || 'http://localhost:8080';
const TOKEN = __ENV.ACCESS_TOKEN || '';

const headers = {
  'Content-Type': 'application/json',
  Authorization: `Bearer ${TOKEN}`,
};

// Track baseline latency ƒë·ªÉ t√≠nh recovery
let baselineLatency = 0;
let lastSpikeEnd = 0;

export default function () {
  const payload = JSON.stringify({
    originText: 'UIT Campus',
    destText: 'Tan Son Nhat Airport',
    serviceId: 'bike',
  });

  const start = Date.now();
  const res = http.post(`${BASE_URL}/v1/trips`, payload, { headers, timeout: '15s' });
  const duration = Date.now() - start;

  tripLatency.add(duration);

  const success = res.status === 201 || res.status === 402;
  check(res, { 'trip created': () => success });
  
  if (success) {
    errorRate.add(0);
  } else {
    errorRate.add(1);
  }

  // Log during spike phases for visibility
  const elapsed = Date.now() / 1000;
  if (duration > 1000) {
    console.log(`High latency detected: ${duration}ms at ${elapsed.toFixed(0)}s`);
  }

  sleep(0.2 + Math.random() * 0.3);
}

export function handleSummary(data) {
  const tripP50 = data.metrics.trip_create_latency?.values?.med || 0;
  const tripP95 = data.metrics.trip_create_latency?.values?.['p(95)'] || 0;
  const tripP99 = data.metrics.trip_create_latency?.values?.['p(99)'] || 0;
  const tripMax = data.metrics.trip_create_latency?.values?.max || 0;
  const errors = data.metrics.error_rate?.values?.rate || 0;
  const totalReqs = data.metrics.http_reqs?.values?.count || 0;

  console.log('\n=== SPIKE TEST SUMMARY ===');
  console.log(`Normal RPS: ${NORMAL_RPS}`);
  console.log(`First Spike: ${NORMAL_RPS * SPIKE_MULTIPLIER} RPS (5x)`);
  console.log(`Second Spike: ${NORMAL_RPS * SPIKE_MULTIPLIER * 2} RPS (10x)`);
  console.log(`Total Requests: ${totalReqs}`);
  console.log(`Error Rate: ${(errors * 100).toFixed(2)}%`);
  console.log('');
  console.log('Latency Distribution:');
  console.log(`  p50: ${tripP50.toFixed(2)}ms`);
  console.log(`  p95: ${tripP95.toFixed(2)}ms`);
  console.log(`  p99: ${tripP99.toFixed(2)}ms`);
  console.log(`  max: ${tripMax.toFixed(2)}ms`);

  // ƒê√°nh gi√° spike handling
  console.log('\n=== SPIKE RESILIENCE ANALYSIS ===');
  
  if (errors < 0.05) {
    console.log('üü¢ Excellent: <5% errors during spikes');
    console.log('   ‚Üí Async queue absorbing burst effectively');
  } else if (errors < 0.10) {
    console.log('üü° Good: 5-10% errors during extreme spike');
    console.log('   ‚Üí Consider pre-warming or more aggressive auto-scaling');
  } else {
    console.log('üî¥ Needs improvement: >10% errors');
    console.log('   ‚Üí Review queue depth limits and consumer scaling');
  }

  if (tripP95 < 1000) {
    console.log('üü¢ Latency well controlled during spikes');
  } else if (tripP95 < 2000) {
    console.log('üü° Latency acceptable but elevated during spikes');
  } else {
    console.log('üî¥ Significant latency degradation during spikes');
  }

  // T√≠nh "spike factor" - t·ª∑ l·ªá p99/p50
  const spikeFactor = tripP50 > 0 ? tripP99 / tripP50 : 0;
  console.log(`\nSpike Factor (p99/p50): ${spikeFactor.toFixed(2)}x`);
  if (spikeFactor < 5) {
    console.log('   ‚Üí Consistent performance under varying load');
  } else if (spikeFactor < 10) {
    console.log('   ‚Üí Some variability during spikes (expected)');
  } else {
    console.log('   ‚Üí High variability - may indicate resource contention');
  }

  return {
    stdout: JSON.stringify(data, null, 2),
  };
}
